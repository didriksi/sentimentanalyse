{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download nb_core_news_sm > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.nb.examples import sentences \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import fasttext\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "import random\n",
    "import tqdm\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_split_dataset(metadata_df = None):\n",
    "    \"\"\"Filter out nynorsk, and split into train and test datasets.\n",
    "    \n",
    "    :param metadata_df: pd.DataFrame object with metadata.\n",
    "    \n",
    "    :return: 2-tuple of train and test pd.DataFrames\n",
    "    \"\"\"\n",
    "    if metadata_df is None:\n",
    "        metadata_df = pd.read_json(f\"data/metadata.json\").T\n",
    "        \n",
    "    bokmål_mask = metadata_df.language == \"nb\"\n",
    "    \n",
    "    metadata_df = metadata_df[bokmål_mask]\n",
    "    \n",
    "    train_mask = metadata_df.split == \"train\"\n",
    "    test_mask = metadata_df.split == \"test\"\n",
    "        \n",
    "    return metadata_df[train_mask], metadata_df[test_mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(doc, lemmatizer=None, remove_newlines=False):\n",
    "    \"\"\"Tokenize and lemmatize.\n",
    "    \n",
    "    :param document: String.\n",
    "    :param remove_newlines: Bool, whether to remove newline characters.\n",
    "    :param lemmatizer: Function Str -> iter(Str,)\n",
    "    \n",
    "    :return: [Spacy Doc? object,]\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(doc, str), f\"doc has to be of type str, {type(doc)} is not supported.\"\n",
    "    \n",
    "    if lemmatizer is None:\n",
    "        lemmatizer = spacy.load(\"nb_core_news_sm\")\n",
    "    \n",
    "    if remove_newlines:\n",
    "        doc = re.sub('\\n', '', doc)\n",
    "    \n",
    "    return lemmatizer(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(doc, stop_words, **process_kwargs):\n",
    "    \"\"\"Cleans up document, normalising words and removing stop_words.\n",
    "    \n",
    "    :param doc: [Str]\n",
    "    :param stop_words: [Str] to exclude\n",
    "    :param **process_kwargs: Passed to process_documents\n",
    "    \n",
    "    :return: [[Str]], list of tokens for each doc\n",
    "    \"\"\"\n",
    "    full_list = []\n",
    "    for token in process_documents(doc, **process_kwargs):\n",
    "        if token.lemma_ not in stop_words:\n",
    "            if token.lemma_ in string.punctuation:\n",
    "                full_list.append(token.lemma_)\n",
    "            else:\n",
    "                full_list.append(f\" {token.lemma_}\")\n",
    "    \n",
    "    return full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(metadata_df=None, path=\"data\", ret=[\"rating\", \"authors\"]):\n",
    "    \"\"\"Get documents of a specific type.\n",
    "        \n",
    "    :param path: Str path to folder with test and train folders.\n",
    "    :param dataset: Determines which type to look for. Either `train` or `test`.\n",
    "    :param ret: Columns from each document to return alongside the document itself. [Rating and authors]\n",
    "    \n",
    "    :return: iter(Str,) of documents\n",
    "    \"\"\"\n",
    "    \n",
    "    if metadata_df is None:\n",
    "        metadata_df = pd.read_json(f\"{path}/metadata.json\").T\n",
    "    \n",
    "    full_path = f\"{path}/%s/%s.txt\"\n",
    "    \n",
    "    for (_, review) in metadata_df.iterrows():\n",
    "        document = open(f\"{path}/{review['split']}/{str(review['id']).zfill(6)}.txt\", \"r\").read()\n",
    "        yield document, *[review[col] for col in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_processed_datasets(debug=False, **datasets):\n",
    "    \"\"\"Make fasttext-style dataset, with each line being a text.\n",
    "    \n",
    "    :param debug: Set to true to only process first doc.\n",
    "    :param **datasets: pd.DataFrames of the metadata format\n",
    "    \n",
    "    Create files `../data/processed/<kwarg_key>.txt`, with each line\n",
    "    being on the form `__label__<1-6> <a document, without linebreaks>.\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for split, dataset in datasets.items():\n",
    "        num_docs = len(dataset)\n",
    "        \n",
    "        text_list = []\n",
    "        file = open(f'../data/processed/{split}.txt', 'a')\n",
    "        for doc, rating in tqdm.tqdm(get_documents(path=\"../data\", metadata_df = dataset, ret=[\"rating\"]), total=len(dataset)):\n",
    "            \n",
    "            clean_str = \"\".join(clean_document(doc, stop_words=stop_words, lemmatizer=lemmatizer, remove_newlines=True))\n",
    "            text_list.append(f\"__label__{rating} {clean_str}\\n\")\n",
    "            \n",
    "            if debug:\n",
    "                break\n",
    "                    \n",
    "        random.shuffle(text_list)\n",
    "        \n",
    "        with open(f\"../data/processed/{split}.txt\", \"w\") as file:\n",
    "            file.write(\"\\n\".join(text_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_json(f\"../data/metadata.json\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Vil du overskrive dataen om kjønnet til forfattere? [Y/n]  n\n"
     ]
    }
   ],
   "source": [
    "def set_gender(authors, authors_df):\n",
    "    \"\"\"Gives gender of a list of authors based on labeled names in a df.\n",
    "    \n",
    "    :param authors: [Str,] where each element is an author\n",
    "    :param authors_df: pd.DataFrame with names as index and a column with gender info.\n",
    "    \n",
    "    :return: `m` for male, `k` for female, or `u` for unknown or ambigous.\n",
    "    \"\"\"\n",
    "    if len(authors) == 1:\n",
    "        return authors_df.gender[authors[0]]\n",
    "    else:\n",
    "        gender = authors_df.gender[authors[0]]\n",
    "        for author in authors[1:]:\n",
    "            if gender != authors_df.gender[author]:\n",
    "                return \"u\"\n",
    "        return gender\n",
    "\n",
    "def label_author_gender(metadata_df):\n",
    "    \"\"\"Finds all author names, and prompts user to label their gender.\n",
    "    \n",
    "    Stores author genders in `../data/authors.csv`.\n",
    "    \n",
    "    :param metadata_df: pd.DataFrame\n",
    "    \n",
    "    :return: metadata_df with gender column.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_authors = []\n",
    "    for authors in metadata_df.authors:\n",
    "        all_authors.extend(authors)\n",
    "    all_authors = list(set(all_authors))\n",
    "\n",
    "    first_names = list(set([full_name.split()[0] for full_name in all_authors]))\n",
    "\n",
    "    genders = {}\n",
    "    i = 0\n",
    "    while i < len(first_names):\n",
    "        gender = input(f\"Sex of `{first_names[i]}` ({i}/{len(first_names)})`: \")\n",
    "        if gender.lower() in [\"m\", \"k\", \"u\"]:\n",
    "            genders[first_names[i]] = gender.lower()\n",
    "            i += 1\n",
    "        elif gender.lower() == \"r\":\n",
    "            i -= 1\n",
    "            print(\"Correcting error, type last gender again.\")\n",
    "        else:\n",
    "            print(\"Type either `m` for male, `k` for female, or `u` for unknown/other.\")\n",
    "\n",
    "    authors_df = pd.DataFrame(index=all_authors, data={\"name\": all_authors})\n",
    "\n",
    "    def apply_firstname_gender(full_name):\n",
    "        return genders[full_name.split()[0]]\n",
    "\n",
    "    authors_df[\"gender\"] = authors_df.name.apply(apply_firstname_gender)\n",
    "    authors_df.to_csv(\"../data/authors.csv\")\n",
    "\n",
    "    metadata_df[\"gender\"] = metadata_df.authors.apply(lambda authors: set_gender(authors, authors_df))\n",
    "    \n",
    "    return metadata_df\n",
    "\n",
    "if os.path.exists(\"../data/authors.csv\") or \"gender\" in metadata_df.columns:\n",
    "    overwrite = input(\"Vil du overskrive dataen om kjønnet til forfattere? [Y/n] \").lower()\n",
    "    \n",
    "    if overwrite in [\"y\", \"yes\"]:\n",
    "        metadata_df = label_author_gender(metadata_df)\n",
    "    \n",
    "    if not \"gender\" in metadata_df.columns:\n",
    "        authors_df = pd.read_csv(\"../data/authors.csv\", index_col=\"name\")\n",
    "        metadata_df[\"gender\"] = metadata_df.authors.apply(lambda authors: set_gender(authors, authors_df))\n",
    "else:\n",
    "    metadata_df = label_author_gender(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "k    4.143918\n",
       "m    4.153312\n",
       "u    4.211404\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df[\"rating\"] = metadata_df[\"rating\"].astype(int)\n",
    "metadata_df.groupby(\"gender\")[\"rating\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df, test_metadata_df = filter_split_dataset(metadata_df = metadata_df)\n",
    "datasets = {'train': train_metadata_df, 'test': test_metadata_df}\n",
    "lemmatizer = spacy.load(\"nb_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['og', 'i', 'jeg', 'det', 'at', 'en', 'et', 'den', 'til', 'er', 'som', 'på', 'de', 'med', 'han', 'av', 'ikke', 'der', 'så', 'var', 'meg', 'seg', 'men', 'ett', 'har', 'om', 'vi', 'min', 'mitt', 'ha', 'hadde', 'hun', 'nå', 'over', 'da', 'ved', 'fra', 'du', 'ut', 'sin', 'dem', 'oss', 'opp', 'man', 'kan', 'hans', 'hvor', 'eller', 'hva', 'skal', 'selv', 'sjøl', 'her', 'alle', 'vil', 'bli', 'ble', 'blitt', 'kunne', 'inn', 'når', 'være', 'kom', 'noen', 'noe', 'ville', 'dere', 'som', 'deres', 'kun', 'ja', 'etter', 'ned', 'skulle', 'denne', 'for', 'deg', 'si', 'sine', 'sitt', 'mot', 'å', 'meget', 'hvorfor', 'dette', 'disse', 'uten', 'hvordan', 'ingen', 'din', 'ditt', 'blir', 'samme', 'hvilken', 'hvilke', 'sånn', 'inni', 'mellom', 'vår', 'hver', 'hvem', 'vors', 'hvis', 'både', 'bare', 'enn', 'fordi', 'før', 'mange', 'også', 'slik', 'vært', 'være', 'begge', 'siden', 'henne', 'hennar', 'hennes']\n"
     ]
    }
   ],
   "source": [
    "# Extract stop words in bokmål from http://snowball.tartarus.org/algorithms/norwegian/stop.txt\n",
    "stop_words = []\n",
    "with open(\"../data/stop_words.txt\", \"r\") as stop_words_file:\n",
    "    for line in stop_words_file:\n",
    "        if len(line) >= 2 and line[2] != \"|\":\n",
    "            stop_word, explanation, = line.split(\"|\")\n",
    "            if len(stop_word) > 1 and explanation[-2] != \"*\":\n",
    "                stop_words.append(stop_word.strip())\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Vil du overskrive de prosesserte datasettetene ditt? [Y/n]  \n"
     ]
    }
   ],
   "source": [
    "# Dette lager to datasett, et treningssett og et testsett, for fasttext-modellen\n",
    "# Vi trenger ikke kjøre dette hver gang, bare første gang vi bruker det på en spesifikk datamaskin\n",
    "if any (os.path.exists(f\"../data/processed/{split}.txt\") for split in [\"train\", \"test\"]):\n",
    "    overwrite = input(f\"Vil du overskrive de prosesserte datasettetene ditt? [Y/n] \").lower()\n",
    "    if overwrite in [\"y\", \"yes\"]:\n",
    "        make_processed_datasets(**datasets)\n",
    "else:\n",
    "    make_processed_datasets(**datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"../data/processed/train.txt\", epoch=30, lr=1.0, wordNgrams=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4281, 0.5676243868255081, 0.5676243868255081)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"../data/processed/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(doc, model, lemmatizer=None, stop_words=stop_words):\n",
    "    \"\"\"Process text, and use the model to predict a label.\n",
    "    \n",
    "    :param doc: Str\n",
    "    :param model: Model with predict method.\n",
    "    :lemmatizer: Function Str -> iter(Str,)\n",
    "    \"\"\"\n",
    "    if lemmatizer is None:\n",
    "        lemmatizer = spacy.load(\"nb_core_news_sm\")\n",
    "    \n",
    "    clean_doc = \"\".join(clean_document(doc, stop_words=stop_words, lemmatizer=lemmatizer, remove_newlines=True))\n",
    "    prediction = model.predict(clean_doc)\n",
    "    return prediction[0][0][-1], clean_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4',\n",
       " ' fantastisk film, levere punkt. favorittdel dramatisk scene, hovedperson får vite skjebne.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Dette var en fantastisk film, leverte på alle punkter. Min favorittdel av den var den dramatiske scenen, der hovedpersonen får vite om sin skjebne.\", model, lemmatizer=lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_value(unsorted_dict):\n",
    "    \"\"\"Sorts dictionary by its value\n",
    "    \n",
    "    :param unsorted_dict: Dict\n",
    "    \n",
    "    :return: Sorted dict, descending\n",
    "    \"\"\"\n",
    "    \n",
    "    return {k: v for k, v in sorted(unsorted_dict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencize(lemmatizer=None, **datasets):\n",
    "    \"\"\"Take in datasets, and return all text, split on sentences.\n",
    "    \n",
    "    :param **datasets: pd.DataFrame metadata-style object.\n",
    "    \n",
    "    :return: Dict where each dataset has a list of strings, each being a sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    if lemmatizer is None:\n",
    "        lemmatizer = spacy.load(\"nb_core_news_sm\")\n",
    "    \n",
    "    ret = {}\n",
    "    with tqdm.tqdm(total=sum([len(dataset) for _, dataset in datasets.items()])) as pbar:\n",
    "        for split, dataset in datasets.items():\n",
    "            ret[split] = []\n",
    "            for doc, in get_documents(metadata_df=dataset, path=\"../data\", ret=[]):\n",
    "                pbar.update(1)\n",
    "                for sentence in process_documents(doc, lemmatizer=lemmatizer, remove_newlines=True).sents:\n",
    "                    ret[split].append(sentence.text.split())\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_words(length, **sentence_sets):\n",
    "    \"\"\"Groups words in lists of length == length\n",
    "        \n",
    "    :param length: Int. Number of words in each string to return.\n",
    "    :param **sentence_sets: [Str], where each string is a sentence.\n",
    "    \n",
    "    :return: Dictionary with all unique groups, string : int number of occurences.\n",
    "    \"\"\"\n",
    "    word_groups = {}\n",
    "    with tqdm.tqdm(total = sum([len(sentence_set) for sentence_set in sentence_sets])) as pbar:\n",
    "        for split, sentence_set in sentence_sets.items():\n",
    "            pbar.update(1)\n",
    "            word_groups[split] = []\n",
    "            for sentence in sentence_set:\n",
    "                for i in range(len(sentence) - length):\n",
    "                    word_groups[split].append(\" \".join([sentence[i+ii] for ii in range(length)]))\n",
    "            word_groups[split].sort()\n",
    "            word_groups[split] = {key: len(list(group)) for key, group in groupby(word_groups[split])}\n",
    "            word_groups[split] = sort_by_value(word_groups[split])\n",
    "    return word_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gendered_dataset(dataset):\n",
    "    \"\"\"Split dataset based on gender.\n",
    "    \n",
    "    :param dataset: pd.DataFrame metadata-style object.\n",
    "    \n",
    "    :return: Dict with male, female and unknown pd.DataFrame metadata-style objects\n",
    "    \"\"\"\n",
    "        \n",
    "    return {gender: dataset[dataset.gender == gender] for gender in [\"m\", \"k\", \"u\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_complexity(lemmatizer=None, **sentence_sets):\n",
    "    \"\"\"Finds the average word count per sentence, and char count per word.\n",
    "    \n",
    "    :param lemmatizer:\n",
    "    :param **sentence_sets:\n",
    "    \n",
    "    :return: Dict with same keys as sentence_sets, and 2-tuples with avg word/sent and char/word as values.\n",
    "    \"\"\"\n",
    "    \n",
    "    if lemmatizer is None:\n",
    "        lemmatizer = spacy.load(\"nb_core_news_sm\")\n",
    "        \n",
    "    complexity = {}\n",
    "    for split, sentence_set in sentence_sets.items():\n",
    "        words = 0\n",
    "        chars = 0\n",
    "        for sentence in sentence_set:\n",
    "            words += len(sentence)\n",
    "            chars += len(\"\".join(sentence))\n",
    "        \n",
    "        words_per_sent = words / len(sentence_set)\n",
    "        chars_per_word = chars / words\n",
    "        \n",
    "        complexity[split] = (words_per_sent, chars_per_word)\n",
    "        \n",
    "    return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_ratios(ratio_threshold, absolute_threshold, **word_groups_dicts):\n",
    "    \"\"\"Finds the words that are used most in a group\n",
    "    \n",
    "    TODO: Normalise with regard to amount of words written by each group, and in each tag\n",
    "    \n",
    "    :param ratio_threshold: Float\n",
    "    :param absolute_threshold: Int\n",
    "    :param **word_groups: Dictionary with all unique groups, string : int number of occurences.\n",
    "    \n",
    "    :return: Dictionary with the \n",
    "    \"\"\"\n",
    "    split = list(word_groups_dicts.keys())\n",
    "    split_combos = [(split[i], split[j]) for j in range(len(split)) for i in range(len(split)) if i != j]\n",
    "    \n",
    "    ratios = {}\n",
    "    for split1, split2 in split_combos:\n",
    "        ratios[split1 + split2] = {}\n",
    "        for word_group in word_groups_dicts[split1]:\n",
    "            if word_group in word_groups_dicts[split2] and word_groups_dicts[split2][word_group] >= absolute_threshold:\n",
    "                ratio = word_groups_dicts[split1][word_group]/word_groups_dicts[split2][word_group]\n",
    "                if ratio >= ratio_threshold:\n",
    "                    ratios[split1 + split2][word_group] = ratio\n",
    "        \n",
    "        ratios[split1 + split2] = sort_by_value(ratios[split1 + split2])\n",
    "    \n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Vil du overskrive dataen om setningssammensetning? [Y/n]  n\n"
     ]
    }
   ],
   "source": [
    "gender_dataset = generate_gendered_dataset(datasets[\"train\"])\n",
    "\n",
    "overwrite = \"y\"\n",
    "if os.path.exists(\"../data/sentence_sets.pkl\"):\n",
    "    overwrite = input(\"Vil du overskrive dataen om setningssammensetning? [Y/n] \").lower()\n",
    "    \n",
    "if overwrite in [\"y\", \"yes\"]:\n",
    "    sentence_set = sentencize(lemmatizer=lemmatizer, **gender_dataset)\n",
    "\n",
    "    with open(\"../data/sentence_sets.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(sentence_set, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(\"../data/sentence_sets.pkl\", \"rb\") as handle:\n",
    "        sentence_set = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on finding word groups of length 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:17<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on finding word groups of length 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:27<00:00,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on finding word groups of length 3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:35<00:00, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on finding word groups of length 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:36<00:00, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found word groups for all lengths up to 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_groups = [0 for _ in range(5)]\n",
    "for i in range(1,5):\n",
    "    print(f\"\\rWorking on finding word groups of length {i}\", flush=True, end=\"\")\n",
    "    word_groups[i] = group_words(i, **sentence_set)\n",
    "print(\"Found word groups for all lengths up to 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity = sentence_complexity(lemmatizer=lemmatizer, **sentence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m': (14.401525810052043, 5.1038499318228245), 'k': (14.411139517143269, 5.09687424667392), 'u': (15.272584895537461, 5.011558558532961)}\n"
     ]
    }
   ],
   "source": [
    "print(complexity) # Ikke signifikant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordgrupper med lengde 1\n",
      "   Kvinner mer enn menn:\n",
      "         storyen: 7.2\n",
      "         vurderes: 6.6\n",
      "         service,: 6.3\n",
      "         tilskueren: 5.9\n",
      "         Retten: 5.2\n",
      "         Antall: 4.9\n",
      "         Peers: 4.3\n",
      "         Ferrantes: 4.1\n",
      "         konsept,: 4.0\n",
      "         levendegjør: 3.7\n",
      "   Menn mer enn kvinner:\n",
      "         BESTE: 52.7\n",
      "         sjøl: 23.1\n",
      "         kutt: 20.5\n",
      "         ANBEFALTE: 14.9\n",
      "         time,: 14.9\n",
      "         plater: 14.6\n",
      "         iPhone: 14.5\n",
      "         rockens: 14.5\n",
      "         soloalbum: 13.9\n",
      "         salg: 13.7\n",
      "Ordgrupper med lengde 2\n",
      "   Kvinner mer enn menn:\n",
      "         1 time: 11.8\n",
      "         over all: 7.5\n",
      "         pris og: 7.2\n",
      "         innenfor sin: 7.1\n",
      "         Se traileren: 4.1\n",
      "         Vigdis Hjorth: 4.0\n",
      "         dem imellom: 3.8\n",
      "         av ett: 3.5\n",
      "         Regissøren har: 3.3\n",
      "         på menyen: 3.1\n",
      "   Menn mer enn kvinner:\n",
      "         en sang: 16.7\n",
      "         Oslo Spektrum: 15.3\n",
      "         Of The: 14.7\n",
      "         sånn at: 14.0\n",
      "         sang om: 12.6\n",
      "         du finner: 12.5\n",
      "         og meget: 12.2\n",
      "         2» er: 12.2\n",
      "         sang som: 11.6\n",
      "         Lyden er: 11.3\n",
      "Ordgrupper med lengde 3\n",
      "   Kvinner mer enn menn:\n",
      "         skyldes det at: 3.0\n",
      "         sin evne til: 2.7\n",
      "         ligger som en: 2.6\n",
      "         på bakgrunn av: 2.6\n",
      "         du enig med: 2.5\n",
      "         i rollene som: 2.5\n",
      "         mellom henne og: 2.4\n",
      "         The Walking Dead: 2.4\n",
      "         Er du enig: 2.3\n",
      "         denne romanen er: 2.2\n",
      "   Menn mer enn kvinner:\n",
      "         Denne filmen er: 9.5\n",
      "         lite annet enn: 9.5\n",
      "         et spill som: 8.7\n",
      "         til syvende og: 8.3\n",
      "         tross av at: 8.1\n",
      "         for to år: 8.0\n",
      "         er lov å: 7.8\n",
      "         på høyde med: 7.6\n",
      "         å se ut: 7.5\n",
      "         er åpenbart at: 7.5\n",
      "Ordgrupper med lengde 4\n",
      "   Kvinner mer enn menn:\n",
      "         Er du enig med: 2.5\n",
      "         et bredt spekter av: 2.3\n",
      "         i rollen som en: 1.9\n",
      "         som strever med å: 1.8\n",
      "         gleder meg til å: 1.6\n",
      "         i sterk kontrast til: 1.6\n",
      "         som sliter med å: 1.6\n",
      "         av det som gjør: 1.6\n",
      "         lene seg tilbake og: 1.6\n",
      "         tross for at hun: 1.6\n",
      "   Menn mer enn kvinner:\n",
      "         å se ut som: 8.5\n",
      "         høres ut som om: 8.3\n",
      "         til syvende og sist: 7.8\n",
      "         og ser ut som: 6.8\n",
      "         er i stand til: 6.7\n",
      "         høres ut som en: 6.7\n",
      "         Det er i det: 6.4\n",
      "         Det er kanskje ikke: 6.1\n",
      "         ingen grunn til å: 5.8\n",
      "         er det umulig å: 5.6\n"
     ]
    }
   ],
   "source": [
    "for i, _word_groups in enumerate(word_groups[1:]):\n",
    "    ratios = word_ratios(1.5, 10, **_word_groups)\n",
    "    print(f\"Ordgrupper med lengde {i+1}\")\n",
    "    for split_combos, desc in [(\"km\", \"Kvinner mer enn menn\"), (\"mk\", \"Menn mer enn kvinner\")]:\n",
    "        print(f\"   {desc}:\")\n",
    "        for i, (word, ratio) in enumerate(ratios[split_combos].items()):\n",
    "            if i >= 10:\n",
    "                break\n",
    "            print(f\"         {word}: {ratio:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eec_generator(templates, people, feelings):\n",
    "    \"\"\"Generates corpus with all combinations of templates, people and feelings.\n",
    "    \n",
    "    :param templates: [Str]\n",
    "    :param people: [(Str: id, Str: value)] \n",
    "    :param feelings: [(Str: id, Str: value)]\n",
    "    \n",
    "    :return: 2-tuple og corpus and ids\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    ids = []\n",
    "    for template in templates:\n",
    "        for person in people:\n",
    "            for feeling in feelings:\n",
    "                corpus.append(template.format(person=person[1], feeling=feeling[1]))\n",
    "                ids.append((template, person[0], person[0]))\n",
    "    \n",
    "    return corpus, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\"{person} er {feeling}\",\n",
    "             \"Situasjonen får {person} til å bli {feeling}\",\n",
    "             \"Jeg fikk {person} til å bli {feeling}\"]\n",
    "people = [(\"m\", \"sønnen min\"), (\"k\", \"datteren min\"), (\"m\", \"han\"), (\"k\", \"henne\")]\n",
    "feelings = [(\"anger\", \"sint\"), (\"joy\", \"glad\")]\n",
    "\n",
    "eec_corpus = eec_generator(templates, people, feelings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sønnen min er sint/ sønn sint: 3\n",
      "sønnen min er glad/ sønn glad: 3\n",
      "datteren min er sint/ datter sint: 3\n",
      "datteren min er glad/ datter glad: 3\n",
      "han er sint/ sint: 3\n",
      "han er glad/ glad: 3\n",
      "henne er sint/ sint: 3\n",
      "henne er glad/ glad: 3\n",
      "Situasjonen får sønnen min til å bli sint/ situasjon få sønn sint: 4\n",
      "Situasjonen får sønnen min til å bli glad/ situasjon få sønn glad: 4\n",
      "Situasjonen får datteren min til å bli sint/ situasjon få datter sint: 4\n",
      "Situasjonen får datteren min til å bli glad/ situasjon få datter glad: 4\n",
      "Situasjonen får han til å bli sint/ situasjon få sint: 4\n",
      "Situasjonen får han til å bli glad/ situasjon få glad: 4\n",
      "Situasjonen får henne til å bli sint/ situasjon få sint: 4\n",
      "Situasjonen får henne til å bli glad/ situasjon få glad: 4\n",
      "Jeg fikk sønnen min til å bli sint/ få sønn sint: 3\n",
      "Jeg fikk sønnen min til å bli glad/ få sønn glad: 3\n",
      "Jeg fikk datteren min til å bli sint/ få datter sint: 3\n",
      "Jeg fikk datteren min til å bli glad/ få datter glad: 3\n",
      "Jeg fikk han til å bli sint/ få sint: 3\n",
      "Jeg fikk han til å bli glad/ få glad: 3\n",
      "Jeg fikk henne til å bli sint/ få sint: 3\n",
      "Jeg fikk henne til å bli glad/ få glad: 3\n"
     ]
    }
   ],
   "source": [
    "for prompt, identifier in zip(*eec_corpus):\n",
    "    prediction = predict(prompt, model, lemmatizer=lemmatizer)\n",
    "    print(f\"{prompt}/{prediction[1]}: {prediction[0]}\")\n",
    "# Her ser vi at modellen fungerer dårlig til dette. Muligens delvis pga bias mot korte tekster,\n",
    "# delvis fordi han og hun er i stop_words, og delvis fordi en film kan være god eller dårlig uavhengig\n",
    "# av om protagonisten har det godt eller dårlig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasit er 4, modellen gjetter ('5', ' Bloodline S02 E01- e05familiehemmelighete mørk. Bloodline fjorårets høydepunkt blant dramakrimserie. veldig god sammenskrudd rollegalleri, historie pløye dyp dysfunksjonell familiedynamikk seig intens fortellerstil gjøre nøsting Rayburn-familiens hemmelighet kvalitetsserie. likevel skrike mye sesong 1 ferdig. serie ganske naturlig perfekt slutt. tross sist episode ende liten cliffhange, veldig tilfreds tid tilbrakt Florida. fremdeles mye glede serie fortsette familiesagae. skuespillerprestasjon, atmosfære, god dialog all tid investere karakter gjøre rask glire serieunivers ny. oppleves ta fatt lang seig epilog. stor mysterium drive spenning løse fjor, etterspill nerve. Fortidens løgne brenner under bein kaste handling forlate rayburn-familie sesong. begivenhet slutt forrige sesong skape ny mørk familiehemmelighet ta bra dagslys, bruke hemmelighet egen vinning. par ny familiemedlem ankomme idyllisk strandeiendom, gjøre fortid fortsette kaste skygge middagsbord mor Sally Rayburn( Sissy Spacek). hel gåre rask utmatte kamp holde fasade, bryte sammen mental ta. løgn hemmelighet mørk. gjøre skuespiller serie god. spesiell Kyle Chandler( John) Linda Cardellini() bekle to rollefigur oppleve stor endring hvert ansvarsfølelse gjøre ende tyngst avgjørelse. karakterutviklinge Bloodline god. Andrea Riseborough kompleks Evangeline god tilskudd galleri. serie lide forrige sesongs god rollefigur, spille glimrende Ben Mendelsohn, henvise tilskuerplass hovedhistorie. hemmelighetskremmeri fange oft utsøkt vis foto. kamera fortsette ligge lur enkelt sekvens gi følelse smugtitte egentlig se. fotograf Jaime Reynoso gjøre igjen Floridas naturskjønn kulisse vesentlig del historiens bakteppe. kontrast handling, leverandør Florida-kystens mytologisk kvalitet – farlig sump praktisk skjulested. testere tålmodighet Fortellertempoet fremdeles uvanlig tregt Bloodline. gå femten sekund replikk. fungere veldig god sesong 1. skuespiller mestre kunst holde igjen, seig fortellerstil tålmodighetsprøve overhenge spenningsmysteri lenger dirre bakgrunn. annen tålmodighetsprøve start sesong 2 yngstebror Kevin Reyburn( Norbert Leo Butz). skjør søsken, stadig tilbakevendende utfordring usikkerhet idioti fore gnagsår serieopplevelse min. Serieskaperne Todd A. Kessler, Glenn Kessler Daniel Zelman knallgode utforske konsekvens løgn, hemmelighet halvsannhet. drivstoffe handling spenning. forrige sesong veksle legge framdrift tragisk tilbakeblikk( fortid vise fortsatt, effekt), frampek oppsiktsvekkende drap, politietterforskning god samtale, nesten samtale bruke drive handling framover start sesong 2. stemningslad velspilt drama fremdeles mye god tv få rayburn-familie runde to. Bloodline trenge nok litt mye blod holde spenning oppe. fem episode samtaletungt strand.')\n"
     ]
    }
   ],
   "source": [
    "# Tester at modellen gir andre svar enn 3 og 4, og fungerer litt iallfall\n",
    "doc = open(f\"../data/test/000307.txt\", \"r\").read()\n",
    "clean = clean_document(doc, stop_words, lemmatizer=lemmatizer, remove_newlines=True)\n",
    "print(f\"Fasit er 4, modellen gjetter {predict(doc, model, lemmatizer=lemmatizer)}[0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyseretninger herfra:\n",
    "\n",
    "1) Se om modellen gir bedre, dårligere, eller mer varierende anmeldelser hvis noe handler tydelig om menn enn om kvinner\n",
    "2) Se om modellen gir bedre, dårligere, eller mer varierende anmeldelser hvis ordene som brukes er mer kvinnelige eller mannlige"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sjekke om fordelingen av ord mellom kjønnene kan være tilfeldig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_gender_bias(model, **datasets):\n",
    "    \"\"\"Test the model on datasets, and find distribution of errors in each of them.\n",
    "    \n",
    "    :param model: Fasttext model object.\n",
    "    :param **datasets: pd.DataFrame metadata-style objects.\n",
    "    \"\"\"\n",
    "    ratings = {}\n",
    "    total_rows = sum([len(dataset) for (_, dataset) in datasets.items()])\n",
    "    with tqdm.tqdm(total=total_rows) as pbar:\n",
    "        for split, dataset in datasets.items():\n",
    "            ratings[split] = np.zeros((len(dataset), 2))\n",
    "            for i, (doc, actual_rating) in enumerate(get_documents(path=\"../data\", metadata_df = dataset, ret=[\"rating\"])):\n",
    "                pbar.update(1)\n",
    "                predicted_rating, _ = predict(doc, model, lemmatizer=lemmatizer, stop_words=stop_words)\n",
    "                ratings[split][i] = np.array([actual_rating, predicted_rating])\n",
    "    \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4281/4281 [03:57<00:00, 18.03it/s]\n"
     ]
    }
   ],
   "source": [
    "gender_test_datasets = generate_gendered_dataset(datasets[\"test\"])\n",
    "ratings = test_model_gender_bias(model, **gender_test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: R2 = 0.320. Actual/predicted avg rating = 4.25/4.31\n",
      "K: R2 = 0.362. Actual/predicted avg rating = 4.23/4.27\n",
      "U: R2 = 0.363. Actual/predicted avg rating = 4.08/4.07\n"
     ]
    }
   ],
   "source": [
    "for split, ratings_array in ratings.items():\n",
    "    r2 = r2_score(ratings_array[:,0], ratings_array[:,1])\n",
    "    actual_avg = ratings_array[:,0].mean()\n",
    "    pred_avg = ratings_array[:,1].mean()\n",
    "    print(f\"{split.capitalize()}: R2 = {r2:.3f}. Actual/predicted avg rating = {actual_avg:.2f}/{pred_avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi at modellen ikke har en signifikant bias mot kvinner. Den gjør det også bedre enn baseline-modellene i norec_baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denne fungerer dårligere. For mange bindestreker, kolon og anførselstegn som blir ord\n",
    "def group_words_in_docs(*lengths, **datasets):\n",
    "    \"\"\"Groups words in lists of length == length\n",
    "        \n",
    "    :param *lengths: Int. Number of words in each string to return.\n",
    "    :param **datasets: pd.DataFrame metadata-style objects.\n",
    "    \n",
    "    :return: Dictionary with all unique groups, string : int number of occurences.\n",
    "    \"\"\"\n",
    "    word_groups = {length: {split: [] for split in datasets.keys()} for length in lengths}\n",
    "    with tqdm.tqdm(total = sum([len(dataset) for _, dataset in datasets.items()])) as pbar:\n",
    "        for split, dataset in datasets.items():\n",
    "            for doc, in get_documents(path=\"../data\", metadata_df = dataset, ret=[]):\n",
    "                pbar.update(1)\n",
    "                processed_doc = process_documents(doc, lemmatizer=lemmatizer, remove_newlines=True)\n",
    "                for length in lengths:\n",
    "                    for i in range(len(processed_doc) - length):\n",
    "                        word_groups[length][split].append(\" \".join([processed_doc[i+ii].text for ii in range(length)]))\n",
    "            \n",
    "            for length in lengths:\n",
    "                word_groups[length][split].sort()\n",
    "                word_groups[length][split] = {key: len(list(group)) for key, group in groupby(word_groups[length][split])}\n",
    "                word_groups[length][split] = sort_by_value(word_groups[length][split])\n",
    "    \n",
    "    return word_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27050/27050 [23:16<00:00, 19.37it/s]   \n"
     ]
    }
   ],
   "source": [
    "word_groups2 = group_words_in_docs(1, 2, 3, 4, 5, **{split: gender_dataset[split] for split in [\"m\", \"k\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/word_groups.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(word_groups2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Vil du overskrive dataen om ordgrupper? [Y/n]  n\n"
     ]
    }
   ],
   "source": [
    "overwrite = \"y\"\n",
    "if os.path.exists(\"../data/word_groups.pkl\"):\n",
    "    overwrite = input(\"Vil du overskrive dataen om ordgrupper? [Y/n] \").lower()\n",
    "    \n",
    "if overwrite in [\"y\", \"yes\"]:\n",
    "    word_groups = group_words_in_docs(1, 2, 3, 4, 5, **gender_dataset)\n",
    "\n",
    "    with open(\"../data/sentence_sets.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(word_groups, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(\"../data/sentence_sets.pkl\", \"rb\") as handle:\n",
    "        word_groups = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordgrupper med lengde 1\n",
      "   Kvinner mer enn menn:\n",
      "         TEATER: 11.0\n",
      "         individuelt: 7.9\n",
      "         Lengde: 7.3\n",
      "         oppskrifter: 5.5\n",
      "         vurderes: 5.3\n",
      "         Retten: 5.2\n",
      "         Antall: 4.9\n",
      "         tilskueren: 4.7\n",
      "         storyen: 4.4\n",
      "         Peers: 4.4\n",
      "   Menn mer enn kvinner:\n",
      "         LÅT: 55.6\n",
      "         BESTE: 52.8\n",
      "         Xbox: 44.0\n",
      "         _: 37.2\n",
      "         kutt: 25.6\n",
      "         Blu-ray: 23.7\n",
      "         PS: 23.4\n",
      "         Universal: 22.6\n",
      "         PC: 20.7\n",
      "         tittelkuttet: 18.7\n",
      "Ordgrupper med lengde 2\n",
      "   Kvinner mer enn menn:\n",
      "         . Aldersgrense: 8.3\n",
      "         Lengde :: 7.7\n",
      "         over all: 7.5\n",
      "         , mat: 7.4\n",
      "         pris og: 7.2\n",
      "         innenfor sin: 7.1\n",
      "         og atmosfære: 6.9\n",
      "         . Skuespillere: 6.8\n",
      "         service ,: 6.3\n",
      "         min. Aldersgrense: 6.2\n",
      "   Menn mer enn kvinner:\n",
      "         LÅT :: 55.6\n",
      "         BESTE LÅT: 54.2\n",
      "         . BESTE: 50.6\n",
      "         . PS: 29.0\n",
      "         på Twitter: 19.5\n",
      "         On The: 15.6\n",
      "         KJØP :: 15.5\n",
      "         time ,: 15.0\n",
      "         ANBEFALTE KJØP: 14.8\n",
      "         Of The: 14.3\n",
      "Ordgrupper med lengde 3\n",
      "   Kvinner mer enn menn:\n",
      "         . Aldersgrense :: 9.1\n",
      "         Lengde : 1: 8.1\n",
      "         min. Aldersgrense :: 7.7\n",
      "         . Manus :: 6.6\n",
      "         med flere .: 5.5\n",
      "         egen sjanger .: 5.5\n",
      "         sin egen sjanger: 5.5\n",
      "         . DOMMEN :: 5.4\n",
      "         . HANDLING :: 5.2\n",
      "         anmelderen ? Si: 5.2\n",
      "   Menn mer enn kvinner:\n",
      "         BESTE LÅT :: 54.1\n",
      "         LÅT : «: 53.7\n",
      "         . BESTE LÅT: 50.1\n",
      "         spor : \": 24.0\n",
      "         KJØP : «: 15.0\n",
      "         ANBEFALTE KJØP :: 14.7\n",
      "         år . Regi: 14.4\n",
      "         , mens \": 13.4\n",
      "         \" , \": 13.3\n",
      "         . ANBEFALTE KJØP: 13.2\n",
      "Ordgrupper med lengde 4\n",
      "   Kvinner mer enn menn:\n",
      "         : 15 år .: 10.2\n",
      "         . Aldersgrense : 15: 5.5\n",
      "         anmelderen ? Si din: 5.2\n",
      "         du enig med anmelderen: 5.2\n",
      "         enig med anmelderen ?: 5.2\n",
      "         med anmelderen ? Si: 5.2\n",
      "         år Egnethet : Ungdom/voksen: 4.5\n",
      "         Aldersgrense : 12 år: 3.5\n",
      "         . Nasjonalitet : USA: 3.4\n",
      "         Tillatt for alle .: 3.3\n",
      "   Menn mer enn kvinner:\n",
      "         BESTE LÅT : «: 53.6\n",
      "         . BESTE LÅT :: 50.0\n",
      "         Beste spor : \": 23.9\n",
      "         år . Regi :: 14.4\n",
      "         ANBEFALTE KJØP : «: 14.3\n",
      "         . ANBEFALTE KJØP :: 13.1\n",
      "         Anmeldelsen fortsetter under bildet: 9.5\n",
      "         , for eksempel ,: 8.7\n",
      "         høres ut som om: 8.3\n",
      "         til syvende og sist: 8.2\n",
      "Ordgrupper med lengde 5\n",
      "   Kvinner mer enn menn:\n",
      "         Aldersgrense : 15 år .: 11.0\n",
      "         . Aldersgrense : 15 år: 5.5\n",
      "         Er du enig med anmelderen: 5.2\n",
      "         anmelderen ? Si din mening: 5.2\n",
      "         du enig med anmelderen ?: 5.2\n",
      "         med anmelderen ? Si din: 5.2\n",
      "         enig med anmelderen ? Si: 5.2\n",
      "         Aldersgrense : Tillatt for alle: 2.8\n",
      "         . Beste spor : «: 2.6\n",
      "         . Er du enig med: 2.6\n",
      "   Menn mer enn kvinner:\n",
      "         . BESTE LÅT : «: 49.5\n",
      "         . Beste spor : \": 24.4\n",
      "         . ANBEFALTE KJØP : «: 12.8\n",
      "         er i stand til å: 6.7\n",
      "         , med andre ord .: 6.7\n",
      "         . På den annen side: 6.6\n",
      "         Det er i det hele: 6.1\n",
      "         , for den saks skyld: 6.0\n",
      "         Enig med vår anmelder ?: 5.2\n",
      "         . Og det er en: 5.1\n"
     ]
    }
   ],
   "source": [
    "for length, _word_groups in word_groups2.items():\n",
    "    ratios = word_ratios(1.5, 10, **_word_groups)\n",
    "    print(f\"Ordgrupper med lengde {length}\")\n",
    "    for split_combos, desc in [(\"km\", \"Kvinner mer enn menn\"), (\"mk\", \"Menn mer enn kvinner\")]:\n",
    "        print(f\"   {desc}:\")\n",
    "        for i, (word, ratio) in enumerate(ratios[split_combos].items()):\n",
    "            if i >= 10:\n",
    "                break\n",
    "            print(f\"         {word}: {ratio:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words_in_docs(words, context_chars=200, max_occurences=3, **datasets):\n",
    "    \"\"\"Find examples of a specific string occuring in datasets.\n",
    "    \n",
    "    :param words: Str, the words you are interested in seeing.\n",
    "    :param context_chars: How many charaters to include on either side of the words, in the print. [100]\n",
    "    :param max_occurences: How many occurences you want to find before stopping. [3]\n",
    "    :param **datasets: pd.DataFrame metadata-style objects.\n",
    "    \n",
    "    Prints out the context as fast as it is found.\n",
    "    \n",
    "    :return: Tuple of ids where text was found.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    with tqdm.tqdm(total = sum([len(dataset) for _, dataset in datasets.items()])) as pbar:\n",
    "        for split, dataset in datasets.items():\n",
    "            for doc, doc_id, excerpt in get_documents(path=\"../data\", metadata_df = dataset, ret=[\"id\", \"excerpt\"]):\n",
    "                pbar.update(1)\n",
    "                if doc.find(words) != -1:\n",
    "                    words_idx = doc.find(words)\n",
    "                    print(\"---\")\n",
    "                    print(f\"\\033[1m\\033[95m{excerpt}: \\033[0m\")\n",
    "                    print(\"...\", doc[max(0, words_idx-context_chars):words_idx], end=\"\")\n",
    "                    print(\"\\033[1m\\033[4m\", doc[words_idx:words_idx+len(words)], \"\\033[0m\", end=\"\")\n",
    "                    print(doc[words_idx+len(words): min(len(doc), words_idx+len(words)+context_chars)])\n",
    "                    ids.append(doc_id)\n",
    "                    if len(ids) >= max_occurences:\n",
    "                        print(\"---\")\n",
    "                        print(\"Found max occurences, stopped before searching through entire dataset\")\n",
    "                        return ids\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 77/34478 [00:00<00:44, 769.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\u001b[1m\u001b[95mStilig, underholdende og sofistikert!: \u001b[0m\n",
      "...  på. \n",
      "\n",
      "Gammeldags kvinnesyn \n",
      "\n",
      "Det som vil more og/eller provosere flest i ”Mad Men” er kvinnesynet serien skildrer. \n",
      "Her er mannen den absolutte sjefen, og kvinnen er til for å tjene mannen. \n",
      "Seriens \u001b[1m\u001b[4m kvinner er \u001b[0m inneforstått med det, men er samtidig oppmerksomme på den kraften og innflytelsen de kan ha på menn. \n",
      "Det finnes kvinner i serien som bruker menns kvinnesyn til egen fordel. \n",
      "\n",
      "Samtidig er det interes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2501/34478 [00:00<00:09, 3376.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\u001b[1m\u001b[95mDen tyske filmen ”Den frie vilje” sitter som et knyttneveslag midt i magen.: \u001b[0m\n",
      "... \n",
      "\n",
      "Det er lett å forstå hvilken vei det bærer. \n",
      "Men til tross for det, håper vi for Theo. \n",
      "Filmen forteller ingenting om hans bakgrunn, men vi skjønner at han må være fryktelig ødelagt. \n",
      "\n",
      "Hans hat til \u001b[1m\u001b[4m kvinner er \u001b[0m like intenst som det er uforståelig. \n",
      "Men jeg liker at filmen ikke overforklarer. \n",
      "Vi må selv finne ut av Theos personlighet. \n",
      "Og vi må selv ta stilling til hvorvidt dette er en person vi vil føle sy\n",
      "---\n",
      "\u001b[1m\u001b[95mfint romantisk drama: \u001b[0m\n",
      "... sisk samlivsbrudd. \n",
      "De står foran mølla alle skilte må igjennom, men spørsmålet er om det er dette de egentlig vil. \n",
      "Og kan bruddet leges? \n",
      "\n",
      "Filmens tittel spiller selvsagt på boka ”Menn er fra Mars, \u001b[1m\u001b[4m kvinner er \u001b[0m fra Venus” som forteller om menn og kvinners ulike behov. \n",
      "Du får nok ingen dyptpløyende psykoanalyser i denne filmen, men tekster fra boka, lest av parets sønn, er med på å forklare reaksjonsmønstre\n",
      "---\n",
      "\u001b[1m\u001b[95mElegant og gjennomført: \u001b[0m\n",
      "... Mannssjåvinistisk kvinnesyn \n",
      "\n",
      "Det som vil more og/eller provosere flest i ”Mad Men” er kvinnesynet serien skildrer. \n",
      "Her er mannen den absolutte sjefen, og kvinnen er til for å tjene mannen. \n",
      "Seriens \u001b[1m\u001b[4m kvinner er \u001b[0m inneforstått med det, men er samtidig oppmerksomme på den kraften og innflytelsen de kan ha på menn. \n",
      "Det finnes kvinner i serien som bruker menns kvinnesyn til egen fordel. \n",
      "\n",
      "Samtidig er det interes\n",
      "---\n",
      "\u001b[1m\u001b[95mSpennende etterforskning, skuffende klimaks.: \u001b[0m\n",
      "...  mens klimakset skuffer litt. \n",
      "Kanskje fordi noen av skuespillerne er litt vel opplagte valg. \n",
      "Jeg skjønner raskt hvem som stinker under den rene fasaden. \n",
      "\n",
      "Nivået bør heves ett hakk \n",
      "\n",
      "Menn som hater \u001b[1m\u001b[4m kvinner er \u001b[0m en bok mange har lest. \n",
      "Mange kommer til å se filmen, også. \n",
      "Og det er helt greit, for Stieg Larssons roman har blitt en helt ok krimfilm, med manus av Nikolaj Arcel og Rasmus Heisterberg. \n",
      "\n",
      "Mine for\n",
      "---\n",
      "\u001b[1m\u001b[95mDen ultimate filmen for tenåringsgutter i puberteten.: \u001b[0m\n",
      "... kje den ultimate filmen å få tak i på VHS. \n",
      "\n",
      "Heavy Metal trekker mye inspirasjon fra band med samme sjangerinteresse som filmens navn. \n",
      "\n",
      "Helter, monstere, magi, narkotika, science fiction, dystopi og \u001b[1m\u001b[4m kvinner er \u001b[0m bare noen stikkord som var viktig for tungrocken - og i denne blandingen finner filmen sin rolle som kultfilm. \n",
      "\n",
      "Alle kvinnene som opptrer i filmen er fremstilt fra synspunktet til rockere anno 1981,\n",
      "---\n",
      "\u001b[1m\u001b[95mGedigen actionsmørje med alfahannen!: \u001b[0m\n",
      "... e blod fra en renblodig kvinne, men den nå voksne Conan (Jason Momoa) kommer i veien, på jakt etter hevn. \n",
      "\n",
      "Brutal mannssjåvinist \n",
      "\n",
      "Denne filmen driter i flere former for korrekthet. \n",
      "Menn er sjefer, \u001b[1m\u001b[4m kvinner er \u001b[0m undersåtter. \n",
      "\n",
      "Conan møter riktignok velkommen mostand i Tamara (Rachel Nichols), renblodskvinnen han må beskytte for å lokke til seg Khalar Zym, men han er en skikkelig brutal mannssjåvinist, og beh\n",
      "---\n",
      "\u001b[1m\u001b[95mOppblåst TV-film som har forvillet seg inn på kino.: \u001b[0m\n",
      "... drømmejournalist \n",
      "\n",
      "Nobels testamente preges også av et samfunnsbilde som begynner å bli veldig oppbrukt, der gamle gubber tviholder på makt, mens de egentlig bare burde legge seg ned og dø, mens unge \u001b[1m\u001b[4m kvinner er \u001b[0m den nye vinen. \n",
      "\n",
      "Men Malin Crépin er fin som den nye Annika Bengtzon. \n",
      "Hun viser mot, klokskap og indre styrke. \n",
      "Altså en drømmejournalist. \n",
      "\n",
      "Glimt fra privatlivet \n",
      "\n",
      "Filmen forsøker å krydre historie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4652/34478 [00:01<00:09, 3196.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\u001b[1m\u001b[95mLangtekkelig oppfølger til langtekkelig forgjenger.: \u001b[0m\n",
      "... l. \n",
      "\n",
      "«Luddere» og «gangstere», velkommen til «Frank Miller’s Sin City». \n",
      "(Våg for all del ikke å kalle den noe kortere og greiere enn «FRANK MILLER’S Sin City» – da blir nemlig «skaperen» vred). \n",
      "Der \u001b[1m\u001b[4m kvinner er \u001b[0m sørgende strippere og/eller troløse horer, og menn er infantile, voldelige tosker. \n",
      "\n",
      "Vi har vært her før, som noen vil huske, i den like monotone og monokrome forgjengeren, «Sin City» – unnskyld! \n",
      "«F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 5131/34478 [00:01<00:10, 2811.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\u001b[1m\u001b[95m: \u001b[0m\n",
      "... igjen treffer på en stadig mer nedkjørt Harry Hole. \n",
      "Han må hentes ut av opiumsrusen i Hong Kong, for ytterst motvillig å bistå Oslo-politiet med det de frykter er en ny seriemorder på gang. \n",
      "To unge \u001b[1m\u001b[4m kvinner er \u001b[0m funnet drept med bedøvelsesmiddel i blodet og uforklarlige stikksår i munnen. \n",
      "Det skal vise seg at de er kommet i nærkontakt med det utspekulert sadistiske drapsvåpenet «Leopolds eple». \n",
      "Og ikke så \n",
      "---\n",
      "Found max occurences, stopped before searching through entire dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 3219, 3221, 3463, 3506, 3826, 3831, 3940, 101437, 102139]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_words_in_docs(\"kvinner er\", context_chars=200, max_occurences=10, **gender_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
